---
layout: post
title: Machine Learning
subtitle: An e-portfolio summary of my learning during the machine learning unit
categories: Machine learning
tags: [machine learning, e-portfolio]
---

## Task 1 - Collaborative discussion 

My initial post is shown below. I argued that "blind faith" in technology, despite clear inaccuracies, led to severe human, economic, and reputational costs, underscoring the urgent need for human oversight and ethical frameworks (Wallis, 2021).

![My logo](/assets/images/initialpost.png)  

In my response to Naveed below, I expanded on proactive resilience strategies (e.g., human training) and linked the incident to ethical AI deployment in healthcare, stressing transparency and oversight (Lim et al., 2023).

![My logo](/assets/images/naveedresponse.png)  
![My logo](/assets/images/markresponse.png)  

My summary post is shown below. A key learning point was that technological advancement carries inherent risks, demanding vigilance, comprehensive risk management, and a strong ethical compass to ensure technology serves human well-being (Aldred, 2022).

![My logo](/assets/images/summarypost.png)

For future similar tasks, I would aim to:

Select initial post incidents with more direct links to specific machine learning dataset challenges to explicitly address that learning outcome.
Proactively draw stronger connections to data-related challenges in peer responses, even if the primary incident cause wasn't dataset-specific.


## Task 2- Correlation and regression

Through this task, I was asked to download and manipulate different datasets in Google Colab to explore the data. The first file to be explored was covariance_pearson_correlation.ipynb. In this file, I was able to achieve a variety of different outcomes, including:

**Weakening the positive correlation**

![My logo](/assets/images/covarianceweakerpositive.png)

**Weakening the positive correlation even further**

![My logo](/assets/images/covarianceevenweakerpositive.png)

**Manipulating the data into a strong negative correlation**

![My logo](/assets/images/covariancemadenegative.png)

**Removing correlation entirely**

![My logo](/assets/images/covariancenocorrelation.png)

**Creating a perfect correlation**

![My logo](/assets/images/covarianceperfectpositivecorrelation.png)

The second file upon which I worked was linear_regression.ipynb. Below are some of the outputs I achieved:

**Strengthening the Positive Linear Correlation**

![My logo](/assets/images/linearregstrongpositive.png)

**Creating a Negative Correlation**

![My logo](/assets/images/linearregweaknegcorr.png)

**Introducing an Outlier**

![My logo](/assets/images/linearregoutlier.png)

**Creating a Non-Linear Relationship**

![My logo](/assets/images/linearregnonlinear.png)


The third file with which I worked was the file polynomial_regression.ipynb. Below are some of the outputs I achieved:

**Exaggerating the Cubic Trend**

![My logo](/assets/images/polynomialexaggeratem.png)

**Fitting Simple Linear Data (Underfitting/Overfitting Illustration)**

![My logo](/assets/images/polynomiallinear.png)

**Introducing a Significant Outlier**

![My logo](/assets/images/polynomialoutlier.png)


**Creating a Simple Quadratic (Parabolic) Relationship**

![My logo](/assets/images/polynomialparabola.png)

## Task 3 - The Jaccard Coefficient 
In this task, I was asked to calculate various Jaccard coefficients using a provided dataset. You can see the outcomes below:

![My logo](/assets/images/Jaccard.png) 

## Task 4 - Experimenting with Perceptron Models (Simple, AND Gate, Multi-Layer Perceptron)

**Simple perceptron**

Through this task, I was asked to download and manipulate different Python activities in Google Colab to explore the fundamental principles of a simple perceptron. The primary file explored was simple_perceptron.ipynb. In this file, I was able to achieve a variety of different outcomes, including:

**Observing Input Impact on Perceptron Output:**

![My logo](/assets/images/simpleperceptronexperiment1.png)

![My logo](/assets/images/simpleperceptronoutput1.png)

**Observing Weight Impact on Perceptron Output:**

![My logo](/assets/images/simpleperceptronexperiment2.png)

![My logo](/assets/images/simpleperceptronoutput2.png)

**Identifying Conditions for Perceptron Activation (Threshold):**

![My logo](/assets/images/simpleperceptronexperiment3.png)

![My logo](/assets/images/simpleperceptronoutput3.png)

**Perceptron AND operator**

Through this task, I was asked to download and manipulate different Python activities in Google Colab to explore the fundamental principles of a simple perceptron and its capabilities when learning a logical operator. The first file to be explored was perceptron_AND_operator.ipynb. In this file, I was able to achieve a variety of different outcomes by only changing numerical values, including:

**Accelerating Convergence with an Increased learning_rate**

![My logo](/assets/images/andoperatorinput2.png)

![My logo](/assets/images/andoperatoroutput2.png)

**Observing Slower Convergence with a Decreased learning_rate**

![My logo](/assets/images/andoperatorinput3.png)

![My logo](/assets/images/andoperatoroutput31.png)

![My logo](/assets/images/andoperatoroutput32.png)

**Analyzing the Impact of Different Initial weights on Convergence**


![My logo](/assets/images/andoperatorinput4.png)

![My logo](/assets/images/andoperatoroutput4.png)

**Multi-layer Perceptron for XOR Operator Exploration**

Through this task, I was asked to download and manipulate different Python activities in Google Colab to explore the capabilities of a Multi-Layer Perceptron (MLP) when learning the non-linearly separable XOR logical operator.  In this file, I was able to achieve a variety of different outcomes by adjusting key hyperparameters, including:

**Observing Underfitting with Fewer Epochs**

![My logo](/assets/images/xorinput2.png)
![My logo](/assets/images/xoroutput2.png)

**Analysing Slower Convergence with a Lower Learning Rate**

![My logo](/assets/images/xorinput3.png)
![My logo](/assets/images/xoroutput3.png)

**Exploring the Impact of a Smaller Range of Initial Weights**

![My logo](/assets/images/xorinput4.png)
![My logo](/assets/images/xoroutput4.png)

## Task 5 - Collaborative discussion

This forum explored AI writers (LLMs) and their implications, linking to machine learning, technical risk, and uncertainty (Units 8-10). 

My initial post discussed AI writers' benefits in efficiency and creativity, alongside risks like inaccuracy, bias, and IP challenges (Russell & Norvig, 2021; Hutson, 2021). I emphasised the need to address inherent technical risks.

![My_logo](/assets/images/collab1.png)

Responding to Valentina:

Peer Valentina highlighted AI's efficiency and creativity benefits, balanced against risks of bias, IP, job displacement, and transparency (Guardian, 2024; Times, 2025; U.S. Copyright Office, 2023). My response proposed data governance, human-in-the-loop systems, disclosure standards, and updated legal frameworks to mitigate these issues (Crawford, 2021; Al-Busaidi et al., 2024).

![My_logo](/assets/images/collab2.png)

Responding to Opeyemi:

Peer Opeyemi similarly outlined AI writers' pros and cons, stressing risks like bias, inaccuracy, authorship, and media transparency (Guardian, 2024; Times, 2025; U.S. Copyright Office, 2023). My response underscored rigorous data governance, human oversight, transparency protocols, and continuous legal/ethical development as key preventative measures.

![My_logo](/assets/images/collab3.png)

My summary post synthesized these insights, emphasizing balancing AI's benefits with preventative strategies. It highlighted responsible AI deployment, ethical development, and human-centric principles (European Commission, 2019), concluding that continuous vigilance and transparent human-AI partnership are crucial.

![My_logo](/assets/images/collab4.png)


## Task 6 - Gradient Cost Function

This task explored Gradient Descent by varying the iteration number and learning rate, observing their impact on cost reduction and model convergence. This directly informed understanding of ML algorithm applicability and data challenges.

**High Learning Rate (Divergence)**

Parameters & Observation: With learning_rate = 0.5, cost rapidly diverged, exploding from 89.0 to immense numbers.

Finding: Overly large steps cause the algorithm to overshoot the minimum, leading to instability and complete failure to converge.

![My_logo](/assets/images/gradient1.png)

**Low Learning Rate (Slow Convergence)**

Parameters & Observation: Using learning_rate = 0.001, cost decreased but only reached 1.6470 by iteration 99.

Finding: Tiny steps lead to extremely slow convergence, making the process inefficient and often leaving the model suboptimal within practical iteration limits.

![My_logo](/assets/images/gradient2.png)

**Insufficient Iterations (Incomplete Convergence)**

Parameters & Observation: With iterations = 20 (and learning_rate = 0.08), the cost stopped at 1.5233 at iteration 19.

Finding: Premature termination prevents full convergence, even with a good learning_rate, resulting in a suboptimal model.

![My_logo](/assets/images/gradient3.png)

**Key Learnings and Future Considerations**
These experiments highlight that learning rate and iteration number are critical hyperparameters. Their optimal values are dataset-dependent, emphasising the challenge of tuning and the importance of data preprocessing (like scaling) for algorithm applicability. Effective ML requires balancing these factors to ensure efficient and accurate model learning. Future work could explore the impact of scaling on optimal parameters with more complex datasets.

## Task 7 - CNN model activity

This task explored Convolutional Neural Networks (CNNs) for object recognition using the CIFAR-10 dataset, examining algorithmic components, prediction outcomes, and ethical implications.

**Ethical & Social Implications of CNNs**
CNN technology presents significant ethical challenges:

Bias & Discrimination: Models can amplify biases from training data, impacting fairness in applications like facial recognition.

Privacy & Surveillance: CNNs enable powerful monitoring, raising privacy concerns.

Reliability & Accountability: Model errors can have severe consequences, complicated by the "black box" nature of CNNs.

Misinformation: CNNs contribute to deepfakes and the spread of false information.

Image 4: Predicted 'deer', but was actually 'frog' – a misclassification highlighting visual ambiguity.

![My_logo](/assets/images/CNN4.png)

Image 9: Correctly predicted 'automobile'.

![My_logo](/assets/images/CNN9.png)

Image 11: Correctly predicted 'truck'.

![My_logo](/assets/images/CNN11.png)

## Task 8 - Model performance measurement

TEST 1: Model Complexity (Regularisation) Impact on AUC
Logistic Regression performance was assessed with varying regularisation (C) on a classification dataset.

C = 0.01 (Strong Reg): Training AUC: 0.9778, Test AUC: 0.9972. Model generalized excellently, even outperforming training slightly.

C = 1.0 (Moderate Reg): Training AUC: 0.9933, Test AUC: 0.9978. Achieved the highest test AUC, indicating near-optimal balance and excellent generalisation.

C = 100.0 (Weak Reg): Training AUC: 0.9955, Test AUC: 0.9956. Showed a minor overfitting trend (Training AUC slightly higher than Test AUC), but overall performance remained very high.

Takeaway: The model achieved consistently high, near-perfect AUCs across regularization strengths, indicating strong suitability for this dataset.

TEST 2: Class Imbalance Impact on F1-Score & Precision/Recall
Tested on a highly imbalanced dataset (Majority: 289 samples; Minority: 11 samples, ~95:5 ratio).

Overall Accuracy: 0.9933. (appears high).

Class 0 (Majority): Precision: 1.00, Recall: 0.99, F1-score: 1.00 (Excellent).

Class 1 (Minority): Precision: 0.85, Recall: 1.00, F1-score: 0.92.

Takeaway: High overall accuracy was misleading. While all 11 minority instances were recalled, 15% of positive predictions for the minority class were false positives (Precision 0.85). This emphasizes the critical role of per-class metrics (Precision, Recall, F1) for fair evaluation in imbalanced scenarios.

TEST 3: Baseline Performance of a 'Random' Classifier
This test established minimum performance thresholds for useful models.

Classification (AUC): Random Classifier AUC: 0.4910. Confirmed random performance is near 0.50.

Regression (R2): Random Regressor R2: -1.8969. Demonstrated performance significantly worse than simply predicting the mean (R2 < 0).

Takeaway: Any useful ML model must significantly exceed these random baselines (AUC > 0.5, R2 > 0) to be considered valuable.

## Unit 6: Airbnb Pricing in NYC: The Influence of Landmark Proximity A Classical Machine Learning Approach

During unit 6, we were tasked with assessesing machine learning applications to Airbnb business trends using the NYC 2019 dataset. We selected "Track 1" which focuses on Classical ML (Regression & Clustering) for price prediction. 

**Teams propose a business question**
This was perhaps one of the most challenging steps as a group. As we had little understanding of the dataset and the task at hand, though I am proud to say that our question of "how does proximity to famous landmarks influence the rental prices of Airbnb's?" Was my first big contribution to the group project.

**EDA**
Next came the analysis of the plausibility of our approach; the report included numerous visualisations that I created which seemed to support our initial hypothesis. Some of which are below:

![My_logo](/assets/images/airbnbplot1.png)

![My_logo](/assets/images/airbnbplot2.png)

![My_logo](/assets/images/airbnbplot3.png)


These, among other plots created by my peers, encouraged us to continue on this path.

**Analytical report**
Once Naveed had created the initial report, it was passed to me where several changes to wordings were made, the above plots were added and relevant academic sources were included. Once done, the report was passed to another group member to finalise the reoprt into its last iteration. 

## Unit 11: Individual Presentation
My object recognition project focused on using classical machine learning with Support Vector Machines (SVMs) on the CIFAR-10 dataset. This dataset contains 60,000 32x32 images across 10 classes.

For preprocessing, I normalised the image pixel values from 0-255 to a 0-1 range and strategically split the data into training, validation, and test sets. My feature engineering involved flattening pixels into 3072-element vectors. 

I tuned SVM hyperparameters (C, Gamma, and kernel type) using GridSearchCV. I faced memory constraints during this process, which I managed by using smaller data subsets for tuning. The optimal model, an RBF kernel SVM, achieved a test accuracy of 47.66%, significantly outperforming random guessing (10%).

My analysis showed the model struggled more with animal classes (like cats and birds) than with inanimate objects. The confusion matrix visually confirmed these difficulties in distinguishing fine visual differences between similar subjects.

## References

Al-Busaidi, S. et al. (2024) ‘AI-generated content: A systematic review of challenges and opportunities’, Journal of Information Science, 50(1), pp. 104–121.

Aldred, C. (2022) The Great Post Office Scandal. London: Orion Publishing Co.

BCI (2025) Cyber resilience in IT & OT: The foundation for Industry 5.0 and critical infrastructure. Available at: https://www.thebci.org/news/cyber-resilience-in-it-ot-the-foundation-for-industry-5-0-and-critical-infrastructure.html (Accessed: 3 July 2025).

Brennen, J.S. et al. (2018) The Oxford Handbook of the Economics of the Internet. Oxford University Press.

Crawford, K. (2021) Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. New Haven: Yale University Press.

European Commission (2019) Ethics Guidelines for Trustworthy AI.

Floridi, L. and Chiriatti, M. (2020) ‘GPT-3: Its Nature, Scope, Limits, and Consequences’, Minds & Machines, 30(4), pp. 681-694.

Hutson, M. (2021) ‘Robo-writers: the rise and risks of language-generating AI’, Nature, 598(7882), pp. 556-559.

Lim, K.S., Lee, J.S. and Kim, J.C. (2023) 'Human-centered artificial intelligence in healthcare: A review', Journal of Medical Systems, 47(1), p. 2.

McCormack, J. et al. (2019) ‘Autonomy, Authenticity, Authorship and Intention in computer generated art’, EvoMUSART 2019, pp 35-50.

Ribeiro, M.T. et al. (2016) ‘"Why Should I Trust You?": Explaining the Predictions of Any Classifier’, Proceedings of the 22nd ACM SIGKDD International Conference, pp. 1135–1144.

Russell, S. J. and Norvig, P. (2021) Artificial Intelligence: A Modern Approach. 4th edn. Harlow: Pearson Education.

The Guardian (2024) 'AI prompts can boost writers' creativity but result in similar stories, study finds', The Guardian, 12 July.

The Times (2025) 'Magazines caught using AI and fake writers for online stories', The Times, 30 June.

U.S. Copyright Office (2023) 'Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence', Federal Register, 88(52), pp. 16190–16195.

Wallis, N. (2021) The Great Post Office Scandal: The fight to expose a multimillion pound IT disaster which put innocent people in jail. London: Bath Publishing Ltd.

Wang, L. et al. (2021) ‘Automatic text summarisation in healthcare: A systematic review’, Journal of Biomedical Informatics, 113, p. 103606.
