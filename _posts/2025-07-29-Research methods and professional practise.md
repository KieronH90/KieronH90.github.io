---
layout: post
title: Research Methods and Professional Practice
subtitle: A reflective journey
categories: Research
tags: [Research, professional practice]
---

## Task 1 - Ethics in Computing in the age of Generative AI 

The rapid emergence of generative AI from late 2022 has profoundly impacted technology and society, with Computer Science at its core. While AI itself isn't new, this generative iteration demands a re-evaluation of what is normal and the urgent establishment of new rules in order to prevent misuse.
Correa et al. (2023) rightly highlight the critical need to define guiding values for AI. Their observation that "a key challenge... lies in establishing a consensus on these values, given the diverse perspectives of various stakeholders worldwide and the abstraction of normative discourse" accurately reflects the current global AI governance landscape. Countries like the EU, US, and China are adopting varied approaches, underscoring the complexity of unified global frameworks (International Actuarial Association, 2025; Times of India, 2025).

Deckard (2023) notes how generative AI challenges traditional views of tasks requiring creativity and social intelligence, impacting employment and human-AI collaboration. Lee et al. (2025) further suggest that generative AI can reduce cognitive effort and foster over-reliance, potentially diminishing critical thinking. These developments deepen ethical and regulatory complexities as human and machine outputs increasingly blur.
My view is that a fragmented approach to generative AI governance, while understandable, poses significant long-term risks that could lead to unforeseen outcomes. Without global coordination, we risk stifling responsible innovation in some regions while allowing unchecked development in others. Universal challenges like bias, privacy, intellectual property, misinformation, and accountability are not confined by borders (KorumLegal, 2024; Coursera, 2025). Therefore, an effective and ethical course of action must be built on international cooperation and a shared commitment to responsible AI.
The best approach, in my opinion, would be a multi-pronged one. One which prioritises international collaboration on foundational principles while allowing for national and regional specificities.

A. Establish a Global AI Governance Body: Given AI's global impact, a dedicated international body, possibly a new or expanded UN agency, would be crucial. This body would not impose rigid laws but facilitate dialogue, consensus-building, and the development of voluntary, high-level principles and best practices, acting as an intermediary or mediator of discussion between authorities and global powers. The Royal Society (2024) emphasizes the UN's potential for creating a common vocabulary and coordinating minimum standards. Its functions would include:
•	Harmonising ethical guidelines: Building on efforts like UNESCO's, this body would identify common ethical principles (e.g., fairness, transparency, accountability, human oversight) across diverse cultures. Diya (2023) suggests universal human rights principles could guide consensus. Correa et al. (2023) note "transparency," "explainability," "reliability," and "fairness" as globally cited principles.
•	Developing interoperable standards: Work towards technical and interoperability standards for AI systems, particularly for data privacy, security, and explainability. This would facilitate cross-border data flows and ensure a baseline of safety.
•	Knowledge sharing and capacity building: Serve as a hub for research, best practices, and regulatory experiences, supporting developing nations in building AI governance capabilities.
•	Monitoring and incident reporting: Create mechanisms for tracking global AI impact, identifying risks, and coordinating responses to AI-related incidents (e.g., misinformation).
Impact on Legal, Social, and Professional Issues:
•	Legal Issues: This approach would provide a strong normative foundation for national legislation, encouraging legal convergence over time. It would reduce fragmentation, foster legal certainty for international businesses, and inform future international treaties. Addressing intellectual property and accountability globally would lead to more consistent legal precedents.
•	Social Issues: A globally coordinated approach would mitigate harmful AI applications like discriminatory systems or misinformation amplification. Promoting inclusive debates would foster a more equitable distribution of AI's benefits and address power concentration concerns (Michigan Online, 2025). This could also lead to a greater emphasis on societal well-being in AI development.
•	Professional Issues: For computing professionals, this framework would provide clearer ethical guidelines and professional standards, reducing ambiguity and supporting responsible innovation. It would empower professionals to advocate for ethical AI within their organisations, backed by international principles. It could also drive demand for interdisciplinary skills. The BCS (2024) highlights the importance of professional bodies in supporting members facing ethical challenges and advocating for stronger standards. This global framework would bolster such initiatives.

B. National and Regional Implementation with Contextual Adaptability: While global principles are vital, specific regulatory frameworks must be tailored to national contexts.
•	Risk-based regulation: Countries should adopt a risk-based approach, like the EU AI Act, with stricter regulations for high-risk AI applications (e.g., critical infrastructure, healthcare, law enforcement).
•	Public-private partnerships: Governments should collaborate with industry, academia, and civil society to develop practical guidelines and self-regulatory mechanisms, ensuring technical feasibility and responsiveness to rapid technological advancements.
•	Education and public awareness: Invest in public education to increase AI literacy and promote informed discourse about its benefits and risks.
In conclusion, the generative AI revolution offers an opportunity for a new paradigm in global governance. A collaborative, multi-tiered approach, starting with UN-facilitated consensus on high-level principles and cascading into context-specific national regulations, is the most suitable course of action. This framework would safeguard against risks, foster responsible innovation, and ensure that generative AI serves humanity's collective good, addressing the complex legal, social, and professional issues faced by computing professionals.

*References*

BCS, The Chartered Institute for IT. (2024) Living with AI and emerging technologies: Meeting ethical challenges through professional standards. Available at: https://www.bcs.org/articles-opinion-and-research/living-with-ai-and-emerging-technologies-meeting-ethical-challenges-through-professional-standards/ (Accessed: 29 July 2025).
Correa, D., et al. (2023) ‘AI Governance: A Systematic Literature Review’, ResearchGate. Available at: https://www.researchgate.net/publication/382523579_AI_Governance_A_Systematic_Literature_Review (Accessed: 29 July 2025).
Deckard. (2023) Generative AI and the Future of Work: A Reappraisal Working Paper No. 2023. Available at: https://oms-www.files.svdcdn.com/production/downloads/academic/2023-FoW-Working-Paper-Generative-AI-and-the-Future-of-Work-A-Reappraisal-combined.pdf (Accessed: 29 July 2025).
Diya, A. (2023) Applying International Human Rights Principles for AI Governance. CIGI Online. Available at: https://www.cigionline.org/documents/3154/no.196_Diya_clNidFE.pdf (Accessed: 29 July 2025).
Lee, K., Han, J., & Lee, S. (2025) The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers. Microsoft. Available at: https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf (Accessed: 29 July 2025).
The Royal Society. (2024) The United Nations' role in international AI governance. Available at: https://royalsociety.org/-/media/policy/publications/2024/un-role-in-international-ai-governance.pdf (Accessed: 29 July 2025).

## Task 2 - Collaborative Learning Discussion

In this task, we were asked to analyse an ACM ethics case, applying ACM/BCS codes, and discussing legal, social, and professional impacts. We chose Corazón's medical implant case, scrutinising its 'negligible risk' assessment of a vulnerability. Our analysis highlighted the critical need for integrity and patient safety in computing professionalism. Below is a screenshot of my initial post:

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/Collaborativediscussioninitialpost.png)

Next, we were required to respond to 3 of the posts that had been written by our peers. Below are each of the posts, followed by my response:

*Julius*
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionJulispost.png)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionJulisresponse.png)

*Shraddha*
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionShraddhapost.png)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionShraddharesponse.png)

*Valentina*
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionValentinapost.png)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionValentinaresponse.png)

Finally, I was asked to write a post summarising the discussions held and to reflect on how this impacted upon my professional opinions:

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/Collaborativediscussionsummarypost.png)

## Task 3 - Literature Review Overview

In this task, we were asked to create an outline for the approach we plan to take when writing our literature review later in the module. The plan and structure that I formulated is as follows:

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/literatureoverviewpage1.png)
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/literatureoverviewpage2.png)
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/literatureoverviewpage3.png)

This approach was accepted with overwhelmingly positive feedback, with some crucial small changes to be made in order to improve upon my final submission. 

## Task 4 -Inappropriate Use of Surveys

This entry examines the unethical use of surveys, where data collection is presented under false pretences. The Cambridge Analytica (CA) scandal is the primary case study, followed by other deceptive practices.

1. Case Study: Cambridge Analytica (CA)
The CA scandal revealed how a seemingly harmless Facebook survey app, "thisisyourdigitallife," was used for unethical data harvesting (Confessore, 2018).

How it Happened: A researcher, Aleksandr Kogan, paid a few hundred thousand users to take a personality quiz. In doing so, Facebook's API allowed his app to also harvest the personal data of their entire friend networks—tens of millions of people who never consented. Kogan then violated Facebook's policies by selling this data to Cambridge Analytica.

Why it was used: CA used the data to build detailed psychographic profiles of voters. These profiles were then used to create and target highly personalised, manipulative political advertising during major political events like the 2016 US election and Brexit.

2. Further Examples of Survey Misuse
Push Polling: This is a political campaign tactic masquerading as a poll. An operative calls a voter and asks leading or slanderous questions ("Would you still vote for Candidate X if you knew they were being investigated for corruption?"). The goal is not to collect data, but to plant negative information and influence the vote.

'Sugging' (Selling Under the Guise of Research): This is a deceptive sales technique. A "researcher" asks survey-like questions to qualify a person as a sales lead ("Do you travel often?"). Once qualified, the interaction pivots to a sales pitch ("Since you travel, you'd be perfect for our new credit card.").

3. Ethical, Social, Legal, and Professional Impacts
All three examples are built on a core deception, leading to severe, overlapping consequences.

Cambridge Analytica: This was a catastrophic failure of informed consent and a direct violation of the ACM code to "Avoid Harm" (ACM, 2018). It caused a massive erosion of public trust in technology and democratic processes. Legally, it resulted in a $5 billion FTC fine for Facebook (FTC, 2019) and accelerated data privacy laws like the GDPR. For the professionals involved, it was a complete breach of ethics, using their skills for societal harm.

Push Polling: This practice is fundamentally dishonest. It pollutes the public discourse with misinformation, increases voter cynicism, and damages the credibility of legitimate polling. It is banned by all professional research bodies as unethical.

'Sugging': This is a deceptive bait-and-switch that exploits public trust. Its main social harm is creating "survey fatigue," which makes the public unwilling to participate in legitimate academic or government research. It is universally condemned and prohibited by market research codes of conduct (MRS, n.d.).

References
ACM (2018) ACM Code of Ethics and Professional Conduct. Available at: https://www.acm.org/code-of-ethics (Accessed: 18 October 2025).

Confessore, N. (2018) 'Cambridge Analytica and Facebook: The Scandal and the Fallout, Explained', The New York Times, 4 April. Available at: https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html (Accessed: 18 October 2025).

FTC (2019) FTC Imposes $5 Billion Penalty and Sweeping New Privacy Restrictions on Facebook. Available at: https://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook (Accessed: 18 October 2025).

MRS (n.d.) Sugging & Frugging. Available at: https://www.mrs.org.uk/research/sugging-frugging (Accessed: 18 October 2025).

## Task 4 -Inappropriate Use of Surveys

For this task, I was asked to critically analyse a questionnaire of my choice. I selected this health questionnaire from the Oxford University Hospital NHS Trust (a snippet is shown below)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/Questionnaireanalysissnippet.png)

This document is a pre-operative health screening questionnaire designed to assess patient risk and accessibility needs. While comprehensive in its topics, I find its format and question design are flawed. These issues could lead to patient confusion, inaccurate data, and potentially missed clinical risks.

The format is the most significant weakness. The table layout visually disconnects questions from their "Yes/No" checkboxes, which are on the far right. This increases cognitive load and the risk of error. Furthermore, the "Click here to add comment" fields are a clunky user interface choice, far less intuitive than a simple web form.

The question wording is also problematic.


Ambiguity: Q11 ("Problematic wheezing") and Q13 ("significant infections") use subjective words that require a patient to make a clinical judgment they are unqualified for. This is a common flaw that can damage data validity (Rattray and Jones, 2007).

Contradiction: Q5 (blood pressure) is contradictory. It asks about "Uncontrolled" high blood pressure but then instructs patients who take medication (and may be well-controlled) to tick "Yes," making the resulting data unreliable.


Redundancy: Q25 ("More than 3 prescribed medicines?") is redundant, as Q30 asks for a complete list.

In contrast, Q31 (Functional capacity) is an excellent question. It uses a validated scale of everyday activities to estimate a patient's Metabolic Equivalents (METS), which is a strong predictor of perioperative risk (Mohan et al., 2021).

Recommendations for Improvement
I believe the questionnaire could be vastly improved with three key changes:

Re-format: Convert this from a Word document to a single-column web form. Place "Yes/No" options immediately adjacent to their question.

Rewrite Ambiguous Questions: Replace subjective words with objective questions.

Rewrite Q5: Split it into "5a. Have you been diagnosed with high blood pressure?" and "5b. Do you take medication for it?"

Rewrite Q11: Change to "Have you been diagnosed with asthma or COPD?"

Streamline Sections: Remove redundant questions like Q25. Move the "Please list all... medications" (Q30) to the top of the medication section to serve as the primary source of information.

References
Mohan, R., D'Souza, R. and Abd-Elsayed, A. (2021) 'Functional Capacity Evaluation in Preoperative Assessment', Current Pain and Headache Reports, 25(9), p. 58.

Rattray, J. and Jones, M.C. (2007) 'Essential elements of questionnaire design and development', Journal of Clinical Nursing, 16(2), pp. 234-243.
