---
layout: post
title: Research Methods and Professional Practice
subtitle: A reflective journey
categories: Research
tags: [Research, professional practice]
---

## Task 1 - Ethics in Computing in the age of Generative AI 

The rapid emergence of generative AI from late 2022 has profoundly impacted technology and society, with Computer Science at its core. While AI itself isn't new, this generative iteration demands a re-evaluation of what is normal and the urgent establishment of new rules in order to prevent misuse.
Correa et al. (2023) rightly highlight the critical need to define guiding values for AI. Their observation that "a key challenge... lies in establishing a consensus on these values, given the diverse perspectives of various stakeholders worldwide and the abstraction of normative discourse" accurately reflects the current global AI governance landscape. Countries like the EU, US, and China are adopting varied approaches, underscoring the complexity of unified global frameworks (International Actuarial Association, 2025; Times of India, 2025).

Deckard (2023) notes how generative AI challenges traditional views of tasks requiring creativity and social intelligence, impacting employment and human-AI collaboration. Lee et al. (2025) further suggest that generative AI can reduce cognitive effort and foster over-reliance, potentially diminishing critical thinking. These developments deepen ethical and regulatory complexities as human and machine outputs increasingly blur.
My view is that a fragmented approach to generative AI governance, while understandable, poses significant long-term risks that could lead to unforeseen outcomes. Without global coordination, we risk stifling responsible innovation in some regions while allowing unchecked development in others. Universal challenges like bias, privacy, intellectual property, misinformation, and accountability are not confined by borders (KorumLegal, 2024; Coursera, 2025). Therefore, an effective and ethical course of action must be built on international cooperation and a shared commitment to responsible AI.
The best approach, in my opinion, would be a multi-pronged one. One which prioritises international collaboration on foundational principles while allowing for national and regional specificities.

A. Establish a Global AI Governance Body: Given AI's global impact, a dedicated international body, possibly a new or expanded UN agency, would be crucial. This body would not impose rigid laws but facilitate dialogue, consensus-building, and the development of voluntary, high-level principles and best practices, acting as an intermediary or mediator of discussion between authorities and global powers. The Royal Society (2024) emphasizes the UN's potential for creating a common vocabulary and coordinating minimum standards. Its functions would include:
•	Harmonising ethical guidelines: Building on efforts like UNESCO's, this body would identify common ethical principles (e.g., fairness, transparency, accountability, human oversight) across diverse cultures. Diya (2023) suggests universal human rights principles could guide consensus. Correa et al. (2023) note "transparency," "explainability," "reliability," and "fairness" as globally cited principles.
•	Developing interoperable standards: Work towards technical and interoperability standards for AI systems, particularly for data privacy, security, and explainability. This would facilitate cross-border data flows and ensure a baseline of safety.
•	Knowledge sharing and capacity building: Serve as a hub for research, best practices, and regulatory experiences, supporting developing nations in building AI governance capabilities.
•	Monitoring and incident reporting: Create mechanisms for tracking global AI impact, identifying risks, and coordinating responses to AI-related incidents (e.g., misinformation).
Impact on Legal, Social, and Professional Issues:
•	Legal Issues: This approach would provide a strong normative foundation for national legislation, encouraging legal convergence over time. It would reduce fragmentation, foster legal certainty for international businesses, and inform future international treaties. Addressing intellectual property and accountability globally would lead to more consistent legal precedents.
•	Social Issues: A globally coordinated approach would mitigate harmful AI applications like discriminatory systems or misinformation amplification. Promoting inclusive debates would foster a more equitable distribution of AI's benefits and address power concentration concerns (Michigan Online, 2025). This could also lead to a greater emphasis on societal well-being in AI development.
•	Professional Issues: For computing professionals, this framework would provide clearer ethical guidelines and professional standards, reducing ambiguity and supporting responsible innovation. It would empower professionals to advocate for ethical AI within their organisations, backed by international principles. It could also drive demand for interdisciplinary skills. The BCS (2024) highlights the importance of professional bodies in supporting members facing ethical challenges and advocating for stronger standards. This global framework would bolster such initiatives.

B. National and Regional Implementation with Contextual Adaptability: While global principles are vital, specific regulatory frameworks must be tailored to national contexts.
•	Risk-based regulation: Countries should adopt a risk-based approach, like the EU AI Act, with stricter regulations for high-risk AI applications (e.g., critical infrastructure, healthcare, law enforcement).
•	Public-private partnerships: Governments should collaborate with industry, academia, and civil society to develop practical guidelines and self-regulatory mechanisms, ensuring technical feasibility and responsiveness to rapid technological advancements.
•	Education and public awareness: Invest in public education to increase AI literacy and promote informed discourse about its benefits and risks.
In conclusion, the generative AI revolution offers an opportunity for a new paradigm in global governance. A collaborative, multi-tiered approach, starting with UN-facilitated consensus on high-level principles and cascading into context-specific national regulations, is the most suitable course of action. This framework would safeguard against risks, foster responsible innovation, and ensure that generative AI serves humanity's collective good, addressing the complex legal, social, and professional issues faced by computing professionals.

*References*

BCS, The Chartered Institute for IT. (2024) Living with AI and emerging technologies: Meeting ethical challenges through professional standards. Available at: https://www.bcs.org/articles-opinion-and-research/living-with-ai-and-emerging-technologies-meeting-ethical-challenges-through-professional-standards/ (Accessed: 29 July 2025).
Correa, D., et al. (2023) ‘AI Governance: A Systematic Literature Review’, ResearchGate. Available at: https://www.researchgate.net/publication/382523579_AI_Governance_A_Systematic_Literature_Review (Accessed: 29 July 2025).
Deckard. (2023) Generative AI and the Future of Work: A Reappraisal Working Paper No. 2023. Available at: https://oms-www.files.svdcdn.com/production/downloads/academic/2023-FoW-Working-Paper-Generative-AI-and-the-Future-of-Work-A-Reappraisal-combined.pdf (Accessed: 29 July 2025).
Diya, A. (2023) Applying International Human Rights Principles for AI Governance. CIGI Online. Available at: https://www.cigionline.org/documents/3154/no.196_Diya_clNidFE.pdf (Accessed: 29 July 2025).
Lee, K., Han, J., & Lee, S. (2025) The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers. Microsoft. Available at: https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf (Accessed: 29 July 2025).
The Royal Society. (2024) The United Nations' role in international AI governance. Available at: https://royalsociety.org/-/media/policy/publications/2024/un-role-in-international-ai-governance.pdf (Accessed: 29 July 2025).

## Task 2 - Collaborative Learning Discussion

In this task, we were asked to analyse an ACM ethics case, applying ACM/BCS codes, and discussing legal, social, and professional impacts. We chose Corazón's medical implant case, scrutinising its 'negligible risk' assessment of a vulnerability. Our analysis highlighted the critical need for integrity and patient safety in computing professionalism. Below is a screenshot of my initial post:

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/Collaborativediscussioninitialpost.png)

Next, we were required to respond to 3 of the posts that had been written by our peers. Below are each of the posts, followed by my response:

*Julius*
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionJulispost.png)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionJulisresponse.png)

*Shraddha*
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionShraddhapost.png)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionShraddharesponse.png)

*Valentina*
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionValentinapost.png)

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/CollaborativediscussionValentinaresponse.png)

## Task 3 - Literature Review Overview

In this task, we were asked to create an outline for the approach we plan to take when writing our literature review later in the module. The plan and structure that I formulated is as follows:

![My logo](/assets/images/ResearchMethodsandProfessionalPractice/literatureoverviewpage1.png)
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/literatureoverviewpage2.png)
![My logo](/assets/images/ResearchMethodsandProfessionalPractice/literatureoverviewpage3.png)
