# Unit 1 Reflection

This introductory unit re-introduced me to the world of big data, its characteristics, and the challenges of managing 
its exponential growth and complexity. I explored methodologies, tools, techniques, and strategies for handling 
big data, specifically focusing on data security requirements. Learning about these challenges and the skills 
needed to develop robust data management systems was initially daunting, but ultimately motivating as I began to 
grasp the potential of big data and the importance of secure data handling.

# Unit 2 reflection

This unit proved a significant learning experience, beginning with the challenge of understanding the breadth of data 
formats. Through systematic exploration of their impact on storage and application, a clearer understanding emerged. 
The study of APIs and their Python integration, while demanding, proved highly rewarding, reinforcing core concepts 
and enhancing comprehension of contemporary data handling practices.

# Unit 3 reflection

This unit included our first collaborative task, which required us to discuss the rationale behind the Internet of 
things (IoT). This task allowed me to explore interesting new ideas along with some of my peers. The details of this 
task are included in the main e-portfolio for this unit. 

It also included a secondary task, based on Web Scraping. This task was perhaps one of the most frustrating tasks that
I have come across during my studies so far, as it is a completely new skill to me. This fact, coupled with the fact that
many major websites have preventative measures in place to prevent web scraping, made this task very difficult to complete.

# Unit 4 reflection

This unit introduced data cleaning and transformation concepts, emphasizing the data management pipeline as a guiding framework. 
I examined factors influencing data cleaning and explored requirements critical for effective data design and process automation. 
Understanding these factors and the pipeline's structure provided a solid foundation for practical data cleaning and 
transformation tasks, including the assessment within this unit.

# Unit 5 reflection

Unit 5's hands-on approach to data cleaning with Python was a steep learning curve. Working with the complex UNICEF data presented 
numerous frustrating obstacles, particularly when trying to master web scraping and efficiently automate cleaning processes. 
While grasping the intricacies of database representation and data models required significant effort and patience, the eventual 
understanding of clear, focused automation made the struggle worthwhile.

# Unit 6 reflection

Unit 6 was probably the most enjoyable of the module so far. Being able to collaborate with my peers to create a piece of work was 
fascinating and engaging. We worked well together, covering the gaps in one another's knowledge, to create what I felt was a well-structured 
and coherent project. I felt that my biggest contributions were both academic, by sourcing research to support our efforts, and logistical 
as my real-life experiences and past employments allowed for a different perspective on the task requirements.

# Unit 7

This unit contained 2 interesting tasks. One on the normalisation of data for better use in databases, and the other to then build a relational 
database using the data obtained in the normalisation task. I felt as though both of these tasks gave me a much more in-depth understanding of databases,
their data and their structure after getting some hands-on experience working with them (however basic).

# Unit 8 reflection



